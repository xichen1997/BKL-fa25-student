{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c69fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANT: On Colab, we expect your homework to be in the cs189 folder\n",
    "## Please contact staff if you encounter any problems with installing dependencies\n",
    "import sys\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %cd /content/drive/MyDrive/cs189/hw/hw0_demo\n",
    "    %pip install -r ./requirements.txt\n",
    "    !pip install -U kaleido plotly\n",
    "    import kaleido\n",
    "    kaleido.get_chrome_sync()\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = pio.renderers.default + \"+png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5d90e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba97cff1",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "\n",
    "<h1 class=\"cal cal-h1\">Homework 0 â€“ Homework Submission Demo!</h1>\n",
    "\n",
    "Welcome to Homework 0!\n",
    "\n",
    "---\n",
    "\n",
    "## Due Date: Friday, September 27, 11:59 PM\n",
    "\n",
    "This assignment is due on **Friday, September 27, at 11:59 PM**. You must submit your work to Gradescope by this deadline. Please refer to the syllabus for the [Slip Day policy](https://eecs189.org/fa25/syllabus/#slip-days). No late submissions will be accepted beyond the details outlined in the Slip Day policy.\n",
    "\n",
    "### Submission Tips:\n",
    "- **Plan ahead**: We strongly encourage you to submit your work several hours before the deadline. This will give you ample time to address any submission issues.\n",
    "- **Reach out for help early**: If you encounter difficulties, contact course staff well before the deadline. While we are happy to assist with submission issues, we cannot guarantee responses to last-minute requests.\n",
    "\n",
    "---\n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "You will complete all the TODOs in the notebook, which include both coding and written response questions. Some tasks are open-ended, which allows you to explore and experiment with different approaches.\n",
    "\n",
    "### Key Learning Objectives:\n",
    "1. Learn how to complete and submit a coding assignment for CS 189/289.\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "### Grading Breakdown\n",
    "\n",
    "| Question | Manual Grading? | Points |\n",
    "|----------|-----------------|--------|\n",
    "| 1        | No              | 2      |\n",
    "| 2        | No              | 2      |\n",
    "| 3        | Yes             | 1      |\n",
    "| 4        | Yes             | 1      |\n",
    "| 5        | No              | 2      |\n",
    "| 6        | Yes             | 2      |\n",
    "| **Total**|                 |  **10** |\n",
    "\n",
    "</div>\n",
    "\n",
    "**Note**: \"Manual\" questions are written response questions that will be graded manually by the course staff. All other questions will be graded automatically by the autograder.\n",
    "\n",
    "---\n",
    "\n",
    "### Instructions:\n",
    "1. Carefully read each question and its requirements.\n",
    "2. Complete all TODOs in the notebook. You may add extra lines of code if needed to implement your solution.\n",
    "3. For manual questions, provide clear and concise written responses.\n",
    "4. Test your code thoroughly to ensure it meets the requirements.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torchvision\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib  # For saving/loading the model\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95915f0",
   "metadata": {},
   "source": [
    "### **IMPORTANT:** \n",
    "- Do not change the random seed values!!!\n",
    "- Before you submit your notebook, remember to set `save_models=True` and `load_models=True`. This saves your final models which we will use for the autograder. Set these to false if you are still tweaking your model setup. We have provided code for saving models - **do not change these file names!!**\n",
    "- When uploading your notebook, make sure to include your model file `classifier.joblib` in your submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducible results\n",
    "SEED = 189\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# IMPORTANT: set save_models to True to save trained models. YOU NEED TO DO THIS FOR THE AUTOGRADER TO WORK.\n",
    "save_models = True\n",
    "load_saved_models = False # After training, you can set this to True to load the saved models and not have to re-train them.\n",
    "IS_GRADING_ENV = os.getenv(\"IS_GRADING_ENV\") == \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d7379",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "**Task**: \n",
    "1. Write a function that takes in a number and returns its square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfaf9f",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    \"\"\"Write a function to return the square of the input\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f235096",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e98ae",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "**Task**:\n",
    "1. Write a function that computes the square of a matrix: ${A^T A}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6064db8",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def square_matrix(A):\n",
    "    \"\"\"Return the square of matrix A\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee3b4c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d753f4",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "**Question**: What is your favorite dinosaur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1896464e",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace99b12",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Question 4\n",
    "\n",
    "**Task:**\n",
    "1. Create a DataFrame of the CIFAR10 dataset with three columns: `image`, `class`, and `label`. The `image` column should be a list of the pixel values, the `class` column should be the integer label (e.g. 0, 1, 2, ..., 9) and the `label` column should be the class label (e.g. 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "2. Group the data in the CIFAR10 dataset by label\n",
    "3. Create a histogram of the label distribution with labels on the x-axis and count on the y-axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80718cbe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b74a1a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Load the FashionMNIST dataset from torchvision\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "class_to_label = {i: class_name for i, class_name in enumerate(train_data.classes)}\n",
    "\n",
    "print(f\"Loaded CIFAR10 dataset with {len(train_data)} samples.\")\n",
    "print(f\"Classes: {train_data.classes}\")\n",
    "print(f\"Image shape: {train_data.data[0].shape}\")\n",
    "print(f\"Image dtype: {train_data.data[0].dtype}\")\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5)\n",
    "for i in range(10):\n",
    "    ax[i // 5, i % 5].imshow(train_data.data[i])\n",
    "    ax[i // 5, i % 5].set_title(class_to_label[train_data.targets[i]])\n",
    "    ax[i // 5, i % 5].axis('off')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb6fa3",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Create a DataFrame with three columns: `image`, `class`, and `label`\n",
    "df = ...\n",
    "\n",
    "print(f\"Columns: {df.columns}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(df.head())\n",
    "\n",
    "# TODO: Group the data in the CIFAR10 dataset by label and create a bar plot of the label distribution\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca58693",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Question 5\n",
    "\n",
    "In this question, we will train a MLPClassifier (Multi-Layer Perceptron Classifier) on the CIFAR10 dataset.\n",
    "\n",
    "**Task**:\n",
    "1. Create a `train_df` and `test_df` from the CIFAR10 dataset using `train_test_split` with `test_size=0.2` and `random_state=SEED`\n",
    "2. Normalize the pixel values of the CIFAR10 dataset using StandardScaler\n",
    "3. Train a MLPClassifier on the normalized training dataset\n",
    "4. Extract the loss curve from the MLPClassifier using the `model.loss_curve_` attribute and plot the loss curve as a line plot with number of epochs on the x-axis and loss on the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6123d520",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\\n\\n Test shape: {test_df.shape}\")\n",
    "print(f\"Train head: {train_df.head()}\\n\\n Test head: {test_df.head()}\")\n",
    "\n",
    "# flatten features into 1D arrays\n",
    "X_train = np.stack(train_df['image'].values).reshape(-1, 32*32*3)\n",
    "y_train = train_df['class'].values\n",
    "X_test = np.stack(test_df['image'].values).reshape(-1, 32*32*3)\n",
    "y_test = test_df['class'].values\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\\t y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\\t y_test shape: {y_test.shape}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "if load_saved_models and os.path.exists('model.joblib'):\n",
    "    model = joblib.load('model.joblib')\n",
    "    # TODO: Plot the loss curve from the loaded model\n",
    "    pass\n",
    "else:\n",
    "    # TODO: Train the model using the scaled traning data and plot the loss curve\n",
    "    pass\n",
    "if save_models:\n",
    "    joblib.dump(model, 'model.joblib')\n",
    "\n",
    "print(f\"Model training accuracy: {model.score(X_train_sc, y_train)}\")\n",
    "print(f\"Model test accuracy: {model.score(X_test_sc, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee3923",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90032a7e",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "Make predictions on the CIFAR10 dataset and plot the accuracy of the predictions.\n",
    "\n",
    "**Task**:\n",
    "1. Make predictions on the `train_df` and `test_df` dataframes using the trained model\n",
    "2. Calculate the accuracy of the predictions\n",
    "3. Create two bar plots of the accuracy of the predictions per class: one bar plot for the training set and one for the test set. The bar plot should have labels (e.g. 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') on the x-axis and accuracy on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf0f847",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c6b89",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Make predictions on train_df and test_df\n",
    "train_df['prediction'] = ...\n",
    "test_df['prediction'] = ...\n",
    "\n",
    "train_df['correct'] = train_df['prediction'] = ...\n",
    "test_df['correct'] = test_df['prediction'] = ...\n",
    "\n",
    "print(f\"Train accuracy: {train_df['correct'].mean()}\")\n",
    "print(f\"Test accuracy: {test_df['correct'].mean()}\")\n",
    "\n",
    "\n",
    "# TODO: Create two bar plots of the accuracy of the predictions per class\n",
    "# with labels on the x-axis and accuracy on the y-axis\n",
    "train_fig = ...\n",
    "test_fig = ...\n",
    "\n",
    "train_fig.show()\n",
    "test_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd8586",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3456995",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Before you submit, ensure `save_models` is true!\n",
    "\n",
    "**Important for grading**: Make sure you set these variables to True at the top of your notebook before submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert save_models and load_saved_models, \"save_models and load_saved_models must be True\"\n",
    "\n",
    "assert os.path.exists('model.joblib'), \"model.joblib should exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9311dcc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this cell if you are running the notebook in Google Colab to install the necessary dependencies, this may take a few minutes\n",
    "if IS_COLAB:\n",
    "    !apt-get install -y texlive texlive-xetex pandoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e54b8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True, files=['model.joblib'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73681846",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> x = 2\n>>> res = square(x)\n>>> expected = 4\n>>> assert res == expected, f'square of {x} returned {res} instead of {expected}'\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X = np.array([[1, 2], [3, 4]])\n>>> res = square_matrix(X)\n>>> expected = np.array([[7, 10], [15, 22]])\n>>> assert np.array_equal(res, expected), f'square of {X} returned {res} instead of {expected}'\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> acc = model.score(X_test_sc, y_test)\n>>> expected = 0.4\n>>> assert acc > expected, f\"Model's test accuracy is {acc}, but expected {expected}\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
