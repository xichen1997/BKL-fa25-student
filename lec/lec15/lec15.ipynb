{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd110d0",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "\n",
    "<h1 class=\"cal cal-h1\">Lecture 15 – CS 189, Fall 2025</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c629ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly import figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "colors = px.colors.qualitative.Plotly\n",
    "px.defaults.width = 800\n",
    "# from ipywidgets import HBox\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3979e",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "\n",
    "<h2 class=\"cal cal-h2\">Numerical Differentiation</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c2ef1c-2a2b-43f6-865b-9d8da118e272",
   "metadata": {},
   "source": [
    "Defining the function `f` that computes the expression \n",
    "$$ \n",
    "f(x_1, x_2) = x_1 x_2 + e^{x_1 x_2} - \\sin(x_2)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ba5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x1, x2):\n",
    "    return x1 * x2 + np.exp(x1 * x2) - np.sin(x2)\n",
    "    \n",
    "print(\"f(1,2)\", f(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cb46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))\n",
    "z = f(x1, x2)   \n",
    "fig = go.Figure()\n",
    "fig.add_surface(x=x1, y=x2, z=z, colorscale=\"viridis\")\n",
    "fig.update_layout(\n",
    "    title=\"Surface Plot of f(x1, x2) = x1 * x2 + exp(x1 * x2) - sin(x2)\",\n",
    "    width=800, height=600,\n",
    "    scene=dict(\n",
    "        xaxis_title='x1', yaxis_title='x2', zaxis_title='f(x1, x2)',\n",
    "        aspectmode='cube'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9aea62",
   "metadata": {},
   "source": [
    "Numerical differentiation is a technique used to approximate the derivative of a function at a given point. It is particularly useful when the function is complex or not easily differentiable analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b559e9c-a06f-4029-933d-270021c3943b",
   "metadata": {},
   "source": [
    "Computing the derivative numerically using finite differences:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_gradient(f, x1, x2, h=1e-8):\n",
    "    \"\"\"\n",
    "    Compute the numerical derivative of f with respect to x1 at (x1, x2)\n",
    "    using central difference.\n",
    "    \"\"\"\n",
    "    return [(f(x1 + h, x2) - f(x1 - h, x2)) / (2 * h), \n",
    "            (f(x1, x2 + h) - f(x1, x2 - h)) / (2 * h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda59116",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_gradient(f, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a140b9",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "\n",
    "<h2 class=\"cal cal-h2\">Symbolic Differentiation</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408a772",
   "metadata": {},
   "source": [
    "We can also derive the gradient using a symbolic algebra library.  This is a powerful technique that allows us to compute the gradient of a function without having to derive it by hand.  We will use the `sympy` library to do this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e315532",
   "metadata": {},
   "source": [
    "Defining the function `f` that computes the expression \n",
    "$$ \n",
    "f(x_1, x_2) = x_1 x_2 + e^{x_1 x_2} - \\sin(x_2)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "# define our symbols\n",
    "x1, x2 = sp.symbols('x1 x2')\n",
    "# Define a symbolic expression for the error\n",
    "E = x1 * x2 + sp.exp(x1 * x2) - sp.sin(x2)\n",
    "# Compute the gradient of E with respect to x1 and x2\n",
    "gE = [sp.diff(E, var) for var in (x1, x2)]\n",
    "gE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde91f94",
   "metadata": {},
   "source": [
    "We can use the symbolic representation to implement the gradient numpy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "gEfun = sp.lambdify((x1, x2), gE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e24c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gEfun(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df78a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_gradient(f, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143b8d6",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "\n",
    "<h2 class=\"cal cal-h2\">Back propagation Example</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242bb33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scalar:\n",
    "    def __init__(self, name, value, parents=[]):\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "        self.parents = parents  # a list of tuples (parent tensor, d self / d parent)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"Addition operator: self + other\"\"\"\n",
    "        if isinstance(other, (int, float)):\n",
    "            return Scalar(f\"({self.name} + {other})\", \n",
    "                          self.value + other, \n",
    "                          [(self, 1.0)])\n",
    "        elif isinstance(other, Scalar):\n",
    "            return Scalar(f\"({self.name} + {other.name})\", \n",
    "                          self.value + other.value, \n",
    "                          [(self, 1.0), (other, 1.0)])\n",
    "        else: \n",
    "            raise TypeError(f\"Unsupported type for addition: {type(other)}\")\n",
    "           \n",
    "    def __radd__(self, other):\n",
    "        \"\"\"Right addition operator: other + self\"\"\"\n",
    "        return self.__add__(other) \n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        \"\"\"Subtraction operator: self - other\"\"\"\n",
    "        if isinstance(other, (int, float)):\n",
    "            return Scalar(f\"({self.name} - {other})\", \n",
    "                            self.value - other, \n",
    "                            [(self, 1.0)])\n",
    "        elif isinstance(other, Scalar):\n",
    "            return Scalar(f\"({self.name} - {other.name})\", \n",
    "                            self.value - other.value, \n",
    "                            [(self, 1.0), (other, -1.0)])\n",
    "        else: \n",
    "            raise TypeError(f\"Unsupported type for subtraction: {type(other)}\")\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        \"\"\"Right subtraction operator: other - self\"\"\"\n",
    "        if isinstance(other, (int, float)):\n",
    "            return Scalar(f\"({other} - {self.name})\",\n",
    "                          other - self.value, \n",
    "                          [(self, -1.0)]) \n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type for subtraction: {type(other)}\")\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        \"\"\"Multiplication operator: self * other\"\"\"\n",
    "        if isinstance(other, (int, float)):\n",
    "            return Scalar(f\"({self.name} * {other})\", \n",
    "                            self.value * other, \n",
    "                            [(self, other)])\n",
    "        elif isinstance(other, Scalar):   \n",
    "            return Scalar(f\"({self.name} * {other.name})\", \n",
    "                            self.value * other.value, \n",
    "                            [(self, other.value), (other, self.value)])\n",
    "        else: \n",
    "            raise TypeError(f\"Unsupported type for multiplication: {type(other)}\")\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        \"\"\"Right multiplication operator: other * self\"\"\"\n",
    "        return self.__mul__(other)\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        \"\"\"Division operator: self / other\"\"\"\n",
    "        if isinstance(other, (int, float)):\n",
    "            if other == 0: \n",
    "                raise ValueError(\"Division by zero\")\n",
    "            return Scalar(f\"({self.name} / {other})\", \n",
    "                            self.value / other, \n",
    "                            [(self, 1.0 / other)])\n",
    "        elif isinstance(other, Scalar):\n",
    "            if other.value == 0: \n",
    "                raise ValueError(\"Division by zero\")\n",
    "            return Scalar(f\"({self.name} / {other.name})\", \n",
    "                            self.value / other.value, \n",
    "                            [(self, 1.0 / other.value), \n",
    "                             (other, -self.value / (other.value ** 2))])\n",
    "        else: \n",
    "            raise TypeError(f\"Unsupported type for division: {type(other)}\")\n",
    "\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        \"\"\"Right division operator: other / self\"\"\"\n",
    "        if not isinstance(other, (int, float)):\n",
    "            raise TypeError(f\"Unsupported type for division: {type(other)}\")\n",
    "        if self.value == 0:\n",
    "            raise ValueError(\"Division by zero\")\n",
    "        # For c/f(x), derivative is -c*f'(x)/f(x)²\n",
    "        return Scalar(f\"({other} / {self.name})\",\n",
    "                        other / self.value, \n",
    "                        [(self, -other / (self.value ** 2))])\n",
    "\n",
    "    def __neg__(self):\n",
    "        \"\"\"Unary negative operator: -self\"\"\"\n",
    "        return Scalar(f\"(-{self.name})\",\n",
    "                        -self.value, \n",
    "                        [(self, -1.0)])\n",
    "\n",
    "    def exp(x):\n",
    "        \"\"\"Exponential function\"\"\"\n",
    "        if not isinstance(x, Scalar):\n",
    "            raise TypeError(f\"Unsupported type for exp: {type(x)}\")\n",
    "        return Scalar(f\"exp({x.name})\", np.exp(x.value), [(x, np.exp(x.value))])\n",
    "    \n",
    "    def sin(x):\n",
    "        \"\"\"Sine function\"\"\"\n",
    "        if not isinstance(x, Scalar):\n",
    "            raise TypeError(f\"Unsupported type for sin: {type(x)}\")\n",
    "        return Scalar(f\"sin({x.name})\", np.sin(x.value), [(x, np.cos(x.value))])\n",
    "    \n",
    "    def ln(x):\n",
    "        \"\"\"Natural logarithm function\"\"\"\n",
    "        if not isinstance(x, Scalar):\n",
    "            raise TypeError(f\"Unsupported type for ln: {type(x)}\")\n",
    "        if x.value <= 0:\n",
    "            raise ValueError(\"Natural logarithm is only defined for positive values\")\n",
    "        return Scalar(f\"ln({x.name})\", np.log(x.value), [(x, 1.0 / x.value)])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def __str__(self):\n",
    "        parents_str = ', '.join([p.name for (p,g) in self.parents])\n",
    "        return f\"Scalar(name='{self.name}', value={self.value}, parents={parents_str})\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c08aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Scalar(\"x\", 1.0)\n",
    "x2 = Scalar(\"y\", 2.0)\n",
    "E = x1 * x2 + Scalar.exp(x1 * x2) - Scalar.sin(x2)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e71847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(final_node):\n",
    "    from collections import defaultdict\n",
    "    # construct a topological ordering of the nodes \n",
    "    # so we can process them in reverse order\n",
    "    def topological_sort(node, visited, sorted_nodes):\n",
    "        if node in visited: return\n",
    "        visited.add(node)\n",
    "        for parent, _ in node.parents:\n",
    "            topological_sort(parent, visited, sorted_nodes)\n",
    "        sorted_nodes.append(node)\n",
    "    sorted_nodes = []\n",
    "    topological_sort(final_node, set(), sorted_nodes)\n",
    "    sorted_nodes.reverse()  # process from output to inputs\n",
    "    \n",
    "    # Compute the adjoints\n",
    "    adjoint = defaultdict(float)\n",
    "    adjoint[final_node] = 1.0  # d final_node / d final_node = 1\n",
    "    for node in sorted_nodes:\n",
    "        # Because we are going in reverse topological order, \n",
    "        # the adjoint of the current node is already computed\n",
    "        for parent, grad in node.parents:\n",
    "            adjoint[parent] += adjoint[node] * grad\n",
    "    return adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjoints = backward(E)\n",
    "adjoints[x1], adjoints[x2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2531c0",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "\n",
    "<h3 class=\"cal cal-h3\">Don't Forget to Topological Sort!</h3>\n",
    "\n",
    "Here is a more \"intuitive\" implementation of backpropagation.  This implementation does not topologically sort the nodes, and therefore does not work in general.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1fb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invalid_backward(final_node):\n",
    "    from collections import defaultdict\n",
    "    queue = [final_node]\n",
    "    visited = set()\n",
    "    adjoint = defaultdict(float)\n",
    "    adjoint[final_node] = 1.0  # d final_node / d final_node = 1\n",
    "    while queue:\n",
    "        node = queue.pop()\n",
    "        if node in visited: continue\n",
    "        visited.add(node)\n",
    "        print(f\"Visiting {node.name}, adjoint={adjoint[node]}\")\n",
    "        for parent, grad in node.parents:\n",
    "            print(f\"   Propagating to {parent.name} with grad {grad}\")\n",
    "            # This is wrong because the adjoint may not be completely computed yet\n",
    "            adjoint[parent] += grad * adjoint[node]\n",
    "            if parent not in visited:\n",
    "                queue.append(parent)\n",
    "    return adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b82918",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjoint = invalid_backward(E)\n",
    "adjoint[x1], adjoint[x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x1 * 2\n",
    "b = 1/a \n",
    "c = Scalar.ln(b)\n",
    "d = c + a\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjoints = backward(d)\n",
    "adjoints[x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b6714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjoints = invalid_backward(d)\n",
    "adjoints[x1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668688d",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "\n",
    "<h2 class=\"cal cal-h2\">Forward Autodiff Example</h2>\n",
    "\n",
    "Bonus material: Forward mode automatic differentiation.  This is a technique that allows us to compute the gradient of a function by propagating derivatives through the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6512cb15",
   "metadata": {},
   "source": [
    "Implementing Forward mode autodiff by defining a custom class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e384fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardVar:\n",
    "    def __init__(self, value, grad, name=None):\n",
    "        self.value = value\n",
    "        self.name = name\n",
    "        self.grad = grad\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"Addition operator: self + other\"\"\"\n",
    "        if not isinstance(other, (int, float, ForwardVar)):\n",
    "            raise TypeError(f\"Unsupported type for addition: {type(other)}\")\n",
    "        if isinstance(other, (int, float)):\n",
    "            return ForwardVar(self.value + other, \n",
    "                              self.grad, \n",
    "                              name=f\"({self.name} + {other})\")\n",
    "        else:\n",
    "            value = self.value + other.value\n",
    "            grad = np.zeros_like(self.grad)\n",
    "            for i in range(len(self.grad)):\n",
    "                grad[i] = self.grad[i] + other.grad[i]\n",
    "            return ForwardVar(value, grad, name=f\"({self.name} + {other.name})\")\n",
    "        \n",
    "    def __radd__(self, other):\n",
    "        return self.__add__(other)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        \"\"\"Subtraction operator: self - other\"\"\"\n",
    "        if not isinstance(other, (int, float, ForwardVar)):\n",
    "            raise TypeError(f\"Unsupported type for subtraction: {type(other)}\")\n",
    "\n",
    "        if isinstance(other, (int, float)):\n",
    "            return ForwardVar(self.value - other, \n",
    "                              self.grad, \n",
    "                              name=f\"({self.name} - {other})\")\n",
    "        else:\n",
    "            value = self.value - other.value\n",
    "            grad = np.zeros_like(self.grad)\n",
    "            for i in range(len(self.grad)):\n",
    "                grad[i] = self.grad[i] - other.grad[i]\n",
    "            return ForwardVar(value, grad, name=f\"({self.name} - {other.name})\")\n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        \"\"\"Right subtraction operator: other - self\"\"\"\n",
    "        if not isinstance(other, (int, float)):\n",
    "            raise TypeError(f\"Unsupported type for subtraction: {type(other)}\")\n",
    "        return ForwardVar(other - self.value, \n",
    "                            -self.grad, \n",
    "                            name=f\"({other} - {self.name})\")\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \"\"\"Multiplication operator: self * other\"\"\"\n",
    "        if not isinstance(other, (int, float, ForwardVar)):\n",
    "            raise TypeError(f\"Unsupported type for multiplication: {type(other)}\")\n",
    "        if isinstance(other, (int, float)):\n",
    "            return ForwardVar(self.value * other, \n",
    "                              self.grad * other, \n",
    "                              name=f\"({self.name} * {other})\")\n",
    "        else:\n",
    "            value = self.value * other.value\n",
    "            grad = np.zeros_like(self.grad)\n",
    "            for i in range(len(self.grad)):\n",
    "                grad[i] = self.grad[i] * other.value + self.value * other.grad[i]\n",
    "            return ForwardVar(value, grad, name=f\"({self.name} * {other.name})\")\n",
    "        \n",
    "    def __rmul__(self, other):\n",
    "        \"\"\"Right multiplication operator: other * self\"\"\"\n",
    "        return self.__mul__(other)\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        \"\"\"Division operator: self / other\"\"\"\n",
    "        if not isinstance(other, (int, float, ForwardVar)):\n",
    "            raise TypeError(f\"Unsupported type for division: {type(other)}\")\n",
    "        if isinstance(other, (int, float)):\n",
    "            if other == 0:\n",
    "                raise ValueError(\"Division by zero\")\n",
    "            return ForwardVar(self.value / other, \n",
    "                              self.grad / other, \n",
    "                              name=f\"({self.name} / {other})\")\n",
    "        else:\n",
    "            if other.value == 0:\n",
    "                raise ValueError(\"Division by zero\")\n",
    "            # product rule: (u/v)' = (u * (1/v))' = u'/v - (u/v^2)*v'\n",
    "            value = self.value / other.value\n",
    "            grad = np.zeros_like(self.grad)\n",
    "            for i in range(len(self.grad)):\n",
    "                grad[i] = self.grad[i] / other.value - (value / (other.value**2)) * other.grad[i]  \n",
    "            return ForwardVar(value, grad, name=f\"({self.name} / {other.name})\")\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        \"\"\"Right division operator: other / self\"\"\"\n",
    "        if not isinstance(other, (int, float)):\n",
    "            raise TypeError(f\"Unsupported type for right division: {type(other)}\")\n",
    "        if self.value == 0:\n",
    "            raise ValueError(\"Division by zero\")\n",
    "        # For c/f(x), derivative is -c*f'(x)/f(x)²\n",
    "        value = other / self.value\n",
    "        grad = np.zeros_like(self.grad)\n",
    "        for i in range(len(self.grad)):\n",
    "            grad[i] = -other * self.grad[i] / (self.value ** 2)\n",
    "        return ForwardVar(value, grad, name=f\"({other} / {self.name})\")\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Unary negative operator: -self\"\"\"\n",
    "        return ForwardVar(-self.value, \n",
    "                          -self.grad, \n",
    "                          name=f\"(-{self.name})\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    # adding print support\n",
    "    def __str__(self):\n",
    "        return f\"ForwardVar(\\n\\tvalue={self.value}, \\n\\tgrad={self.grad}, \\n\\tname='{self.name}')\"\n",
    "\n",
    "def forward_exp(x : ForwardVar):\n",
    "    value = np.exp(x.value)\n",
    "    grad = np.zeros_like(x.grad)\n",
    "    for i in range(len(x.grad)):\n",
    "        grad[i] = x.grad[i] * value\n",
    "    return ForwardVar(value, grad, name=f\"exp({x.name})\")\n",
    "\n",
    "def forward_sin(x : ForwardVar):\n",
    "    value = np.sin(x.value)\n",
    "    grad = np.zeros_like(x.grad)\n",
    "    for i in range(len(x.grad)):\n",
    "        grad[i] = x.grad[i] * np.cos(x.value)\n",
    "    return ForwardVar(value, grad, name=f\"sin({x.name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae054c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = ForwardVar(1, np.array([1., 0.]), name=\"x1\")\n",
    "v2 = ForwardVar(2, np.array([0., 1.]), name=\"x2\")\n",
    "\n",
    "\n",
    "v1 * v2 + forward_exp(v1 * v2) - forward_sin(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b2e6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
